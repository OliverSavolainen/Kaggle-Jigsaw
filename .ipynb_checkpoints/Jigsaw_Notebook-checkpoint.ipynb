{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "train = pd.read_csv('validation_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a dataframe, data separates sentences and shows if they were the less or more toxic one in their pairing\n",
    "train1 = pd.DataFrame(train['less_toxic'])\n",
    "train1.columns = ['sentence']\n",
    "train1['is_toxic'] = 0\n",
    "train2 = pd.DataFrame(train['more_toxic'])\n",
    "train2.columns = ['sentence']\n",
    "train2['is_toxic'] = 1\n",
    "train3 = pd.concat([train1,train2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3['sentence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframe, where there are no repeated sentences in different rows, but there are value counts\n",
    "final_train = train3['sentence'].value_counts().rename_axis('sentence').reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the mean value for a sentence to be the more toxic one\n",
    "def getMean(sentence):\n",
    "    this = train3.loc[train3['sentence'] == sentence]\n",
    "    return sum(this.is_toxic)\n",
    "sumof = final_train.apply(lambda x:getMean(x['sentence']), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train['mean'] = sumof\n",
    "final_train['mean'] = final_train['mean'] / final_train['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.counts.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.rename(columns={'sentence':'the_original_sentence','counts':'the_counts_of_sentences','mean':'the_percentage_for_the_sentence_being_more_toxic'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnetLemmatizer = WordNetLemmatizer()\n",
    "countVect = CountVectorizer()\n",
    "allWordsList = ntlk.word_tokenize(final_train['the_original_sentence'])\n",
    "[wordnetLemmatizer.lemmatize for i,j in pos_tag(allWordsList)]\n",
    "lemmatizedText = [\" \".join([lemma[0] for lemma in text]) for text in allWordsList]\n",
    "count_counts = count_vect.fit_transform(lemmatizedText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toWords(sentence,words,count,mean):\n",
    "    sent = set(sentence.split(\" \"))\n",
    "    for word in sent:\n",
    "        word = word.lower()\n",
    "        word = word.strip(\"/n\")\n",
    "        word = ''.join(e for e in word if e.isalnum())\n",
    "        if word not in words:\n",
    "            words[word] = [1,count,count*mean]\n",
    "        else:\n",
    "            words[word][0] += 1\n",
    "            words[word][1] += count\n",
    "            words[word][2] += count*mean\n",
    "words = {}\n",
    "final_train.apply(lambda x:toWords(x['the_original_sentence'],words,x['the_counts_of_sentences'],x['the_percentage_for_the_sentence_being_more_toxic']), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    if words[word][0] >= 20 and (words[word][1] / words[word][2] < 0.34 or words[word][1] / words[word][2] > 0.67):\n",
    "        final_train[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = final_train[final_train.the_counts_of_sentences > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.dropna(inplace=True)\n",
    "final_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCounts(sentence):\n",
    "    sent = set(sentence.split(\" \"))\n",
    "    for word in sent:\n",
    "        word = word.lower()\n",
    "        word = word.strip(\"/n\")\n",
    "        word = ''.join(e for e in word if e.isalnum())\n",
    "        if word in final_train.columns:\n",
    "            final_train.loc[final_train.the_original_sentence == sentence,word] = 1\n",
    "final_train.apply(lambda x:getCounts(x['the_original_sentence']), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = final_train.drop(columns=['the_original_sentence','the_counts_of_sentences','the_percentage_for_the_sentence_being_more_toxic'])\n",
    "for i in X.columns:\n",
    "    if sum(X.i) <= 2 or sum(X.i) == len(X):\n",
    "        X = X.drop(columns=[i])\n",
    "y_train = final_train['the_percentage_for_the_sentence_being_more_toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#rfc = RandomForestClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestRegressor, found optimized parameters by trying out different values\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "rfr = RandomForestRegressor(n_estimators=10000, max_depth=1000,max_features=\"sqrt\", n_jobs=4, random_state=24)\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(X_train))\n",
    "\n",
    "def build_and_compile_model(norm,activation):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(1329, activation=activation),\n",
    "      layers.Dense(36, activation=activation),\n",
    "      layers.Dense(6, activation=activation),\n",
    "      layers.Dense(2, activation=activation),\n",
    "      layers.Dense(1),\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_squared_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_and_compile_model(normalizer,'relu')\n",
    "history = model.fit(X_train,y_train,validation_split=0.2,verbose=0, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_alpha = 100\n",
    "model = Ridge(alpha=ridge_alpha).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_alpha = 0.001\n",
    "model = Lasso(alpha=lasso_alpha).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv('comments_to_score.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.rename(columns={'text':'the_original_sentence'},inplace=True)\n",
    "for i in X.columns:\n",
    "    subm[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCounts2(sentence):\n",
    "    sent = set(sentence.split(\" \"))\n",
    "    for word in sent:\n",
    "        word = word.lower()\n",
    "        word = word.strip(\"/n\")\n",
    "        word = ''.join(e for e in word if e.isalnum())\n",
    "        if word in final_train.columns:\n",
    "            subm.loc[subm.the_original_sentence == sentence,word] = 1\n",
    "subm.apply(lambda x:getCounts2(x['the_original_sentence']), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = subm.drop(columns=['the_original_sentence','comment_id'])\n",
    "X_test.to_csv('actual.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict(X_test)\n",
    "df = pd.DataFrame({'comment_id':subm['comment_id'],'score':y_prob.squeeze()})\n",
    "df.to_csv('scores4.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
